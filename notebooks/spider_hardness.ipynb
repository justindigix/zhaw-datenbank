{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spider.test_suite_eval.process_sql import get_schema_from_json, get_sql\n",
    "from spider.test_suite_eval.schema import build_schema_mapping, SchemaIndex\n",
    "from spider.test_suite_eval.evaluation import Evaluator\n",
    "import re\n",
    "import json\n",
    "SCHEMA_NAMES = ['OncoMX', 'SDSS', 'StatBot', 'WorldCup']\n",
    "SCHEMA_PATHS = ['oncomx', 'sdss', 'statbot', 'world_cup']\n",
    "\n",
    "def load_schema_dict(names=SCHEMA_NAMES, paths=SCHEMA_PATHS):\n",
    "    schema_dict = {}\n",
    "    for name, path in zip(names, paths):\n",
    "        with open(f'data/{path}/original/tables.json', 'r') as inf:\n",
    "            schema = json.load(inf)[0]\n",
    "        schema_dict[name] = schema\n",
    "    return schema_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict = load_schema_dict()\n",
    "dataset = 'SDSS'\n",
    "schema = schema_dict[dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all functions\n",
    "def get_hardness(query, evaluator, schema_dict):\n",
    "    schema_mapping = build_schema_mapping(schema_dict)\n",
    "    schema = SchemaIndex(\n",
    "        schema_mapping, schema_dict['column_names_original'], schema_dict['table_names_original'])\n",
    "    try:\n",
    "        spider_sql_structure, sql_tokenizer = get_sql(schema, query)\n",
    "        return evaluator.eval_hardness(spider_sql_structure)\n",
    "    except Exception as e:\n",
    "        return f\"\"\"Cannot parese SQL input. Please check your query again\\n\"\"\" \\\n",
    "               f\"\"\"Input: {query}\\nError: {e}\"\"\"\n",
    "\n",
    "def normalize_spaces(match_obj):\n",
    "    for i, _ in enumerate(match_obj.groups(), 1):\n",
    "        if match_obj.group(i) is not None and match_obj.group(i+2) is not None:\n",
    "            return match_obj.group(i) + ' ' + match_obj.group(i+1).strip() + ' ' + match_obj.group(i+2)\n",
    "\n",
    "def normalize_as(match_obj):\n",
    "    reserved_keywords = ['as', 'where', 'order', 'on'\n",
    "                         'group', 'limit', 'join', 'having']\n",
    "    # print(match_obj.groups())\n",
    "    for i, grp in enumerate(match_obj.groups(), 1):\n",
    "        if match_obj.group(i) is not None and match_obj.group(i+1) is not None and match_obj.group(i+2) is not None and match_obj.group(i+2).lower() not in reserved_keywords:\n",
    "            #print(i, match_obj.group(i), match_obj.group(i+1))\n",
    "            if match_obj.group(i+2):\n",
    "                return match_obj.group(i) + ' ' + match_obj.group(i+1).rstrip() + ' AS ' + match_obj.group(i+2).strip()\n",
    "        elif match_obj.group(i) is not None and match_obj.group(\n",
    "                i+1) is not None and match_obj.group(i+2) is not None:\n",
    "            return match_obj.group(i) + ' ' + match_obj.group(i+1).rstrip() + ' ' + match_obj.group(i+2).strip()\n",
    "\n",
    "def quotate_boolean_values(match_obj):\n",
    "    for i, _ in enumerate(match_obj.groups(), 1):\n",
    "        if match_obj.group(i) is not None:\n",
    "            # print(match_obj)\n",
    "            return '\\'' + match_obj.group(i).strip('\\'') + '\\''\n",
    "    \n",
    "def _add_spaces(query):\n",
    "    operators_1 = ['\\+', '\\-', '/', '\\*', '\\=', '>', '<']\n",
    "    operators_2 = ['>=', '<=', '!=', '<>']\n",
    "    ops = operators_2 + operators_1\n",
    "    re_patterns_list = [\n",
    "        f\"(\\w+\\.?\\w*)(\\s*{op}\\s*)([\\\"\\'\\-\\w]+\\.?[\\\"\\'\\w]*)\" for op in ops]\n",
    "    regex = ('|').join(re_patterns_list)\n",
    "    try:\n",
    "        new_query = re.sub(regex, normalize_spaces, query)\n",
    "    except Exception as e:\n",
    "        print(f\"_add_spaces: {query}\")\n",
    "        print(e)\n",
    "        new_query = query\n",
    "    return new_query\n",
    "\n",
    "def _add_as(query):\n",
    "    regex = re.compile(\n",
    "        '(FROM)\\s+([\\w\\_]+)\\s+([\\w\\_]+)|(JOIN)\\s+([\\w\\_]+)\\s+([\\w\\_]+)', flags=re.IGNORECASE)\n",
    "    try:\n",
    "        new_query = re.sub(regex, normalize_as, query)\n",
    "    except Exception as e:\n",
    "        print(f\"_add_as: {query}\")\n",
    "        print(e)\n",
    "        new_query = query\n",
    "    return new_query\n",
    "\n",
    "def _add_quotes(query, keywords=['true', 'false']):\n",
    "\n",
    "    _keywords = [f'\\'{word}\\'' for word in keywords]\n",
    "    # keywords = _keywords + keywords\n",
    "    if isinstance(query, str):\n",
    "        for _k, k in zip(_keywords, keywords):\n",
    "            query = query.replace(_k, k)\n",
    "    regex = re.compile(r'\\b(%s)\\b' % '|'.join(keywords),\n",
    "                       flags=re.IGNORECASE | re.MULTILINE)\n",
    "    # print(regex)\n",
    "    try:\n",
    "        new_query = re.sub(regex, quotate_boolean_values, query)\n",
    "    except Exception as e:\n",
    "        print(f\"_add_quotes: {query}\")\n",
    "        print(e)\n",
    "        new_query = query\n",
    "\n",
    "    return new_query\n",
    "\n",
    "def query_cleaning(query):\n",
    "    \"\"\"todo:\n",
    "    – SELECT * FROM A a JOIN B b ON A.a=B.b WHERE\n",
    "    A.c = true\n",
    "    + SELECT * FROM A AS a JOIN B AS b ON A.a = B.b\n",
    "    WHERE A.c = ’true’ (use keyword \"AS\" explicitly, space\n",
    "    before and after \"=\", and stringfy the boolean value\n",
    "    \"true\"/\"false\")\n",
    "    \"\"\"\n",
    "    # print(query)\n",
    "    res = _add_quotes(_add_as(_add_spaces(query)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator()\n",
    "train_file = f\"data/{dataset.lower()}/seed.json\"\n",
    "dev_file = f\"data/{dataset.lower()}/dev.json\"\n",
    "\n",
    "def get_dataset_hardness(datafile, schema_dict, dataset):\n",
    "    with open(train_file, 'r') as data:\n",
    "        train_data = json.load(data)\n",
    "    res = []\n",
    "    for d in train_data:\n",
    "        query = d['query']\n",
    "        question = d['question']\n",
    "        hardness = get_hardness(query_cleaning(query), Evaluator(), schema_dict[dataset])\n",
    "        temp = {\n",
    "            'db_id': dataset,\n",
    "            'question': question,\n",
    "            'query': query,\n",
    "            'hardness': hardness\n",
    "        }\n",
    "        res.append(temp)\n",
    "    split = datafile.split('/')[-1].split('.')[0]\n",
    "    hardness_output = f\"data/{dataset.lower()}/{split}_hardness.json\"\n",
    "    with open(hardness_output, 'w') as outf:\n",
    "        json.dump(res, outf, indent=4)\n",
    "\n",
    "\n",
    "get_dataset_hardness(train_file, schema_dict, 'SDSS')\n",
    "get_dataset_hardness(dev_file, schema_dict, 'SDSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('\\\\b(true|false)\\\\b', re.IGNORECASE|re.MULTILINE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'extra'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = 'SELECT * FROM disease as d;'\n",
    "query = '''SELECT amount, rank\n",
    "FROM baby_names_favorite_firstname bnff\n",
    "JOIN spatial_unit su ON bnff.spatialunit_uid=su.spatialunit_uid\n",
    "WHERE year = 2014\n",
    "    AND bnff.gender = 'girl'\n",
    "    AND bnff.first_name = 'Lena'\n",
    "    AND su.name = 'Switzerland'\n",
    "    AND su.country = TRUE;\n",
    "'''\n",
    "query = query_cleaning(query)\n",
    "evaluator = Evaluator()\n",
    "res = get_hardness(query, evaluator, schema)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('zhaw-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee90e28e24f847d64b5e2ab743e2358217aed04b10d52cb13ecbfbec1bc91846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
